{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Master`s Degree\\Навчання\\Предмети\\Триместр 3\\ML\\Пр 1\\linear_regression.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master%60s%20Degree/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F/%D0%9F%D1%80%D0%B5%D0%B4%D0%BC%D0%B5%D1%82%D0%B8/%D0%A2%D1%80%D0%B8%D0%BC%D0%B5%D1%81%D1%82%D1%80%203/ML/%D0%9F%D1%80%201/linear_regression.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master%60s%20Degree/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F/%D0%9F%D1%80%D0%B5%D0%B4%D0%BC%D0%B5%D1%82%D0%B8/%D0%A2%D1%80%D0%B8%D0%BC%D0%B5%D1%81%D1%82%D1%80%203/ML/%D0%9F%D1%80%201/linear_regression.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Master%60s%20Degree/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F/%D0%9F%D1%80%D0%B5%D0%B4%D0%BC%D0%B5%D1%82%D0%B8/%D0%A2%D1%80%D0%B8%D0%BC%D0%B5%D1%81%D1%82%D1%80%203/ML/%D0%9F%D1%80%201/linear_regression.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Master%60s%20Degree/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F/%D0%9F%D1%80%D0%B5%D0%B4%D0%BC%D0%B5%D1%82%D0%B8/%D0%A2%D1%80%D0%B8%D0%BC%D0%B5%D1%81%D1%82%D1%80%203/ML/%D0%9F%D1%80%201/linear_regression.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data samples\n",
    "x = np.linspace(-5.0, 5.0, 100)[:, np.newaxis]\n",
    "y = 29 * x + 40 * np.random.rand(100,1)\n",
    "\n",
    "# normalization of input data\n",
    "x /= np.max(x)\n",
    "\n",
    "plt.title('Data samples')\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(x, y)\n",
    "y_hat_sklearn = sklearn_model.predict(x)\n",
    "\n",
    "plt.title('Data samples')\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_hat_sklearn, color='r');\n",
    "\n",
    "print('Sklearn MSE: ', mean_squared_error(y, y_hat_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Linear Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self, weights_init='random', add_bias = True, learning_rate=1e-5, \n",
    "        num_iterations=1000, verbose=False, max_error=1e-5):\n",
    "        ''' Linear regression model using gradient descent \n",
    "\n",
    "        # Arguments\n",
    "            weights_init: str\n",
    "                weights initialization option ['random', 'zeros']\n",
    "            add_bias: bool\n",
    "                whether to add bias term \n",
    "            learning_rate: float\n",
    "                learning rate value for gradient descent\n",
    "            num_iterations: int \n",
    "                maximum number of iterations in gradient descent\n",
    "            verbose: bool\n",
    "                enabling verbose output\n",
    "            max_error: float\n",
    "                error tolerance term, after reaching which we stop gradient descent iterations\n",
    "        '''\n",
    "\n",
    "        self.num_iterations = num_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights_init = weights_init\n",
    "        self.add_bias = add_bias\n",
    "        self.verbose = verbose\n",
    "        self.max_error = max_error\n",
    "    \n",
    "    def initialize_weights(self, n_features):\n",
    "        ''' weights initialization function '''\n",
    "        if self.weights_init == 'random':\n",
    "            ################\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            weights = # TODO\n",
    "\n",
    "            ################\n",
    "        elif self.weights_init == 'zeros':\n",
    "            ################\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            weights = # TODO\n",
    "\n",
    "            ################\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return weights\n",
    "\n",
    "    def cost(self, target, pred):\n",
    "        ''' calculate cost function \n",
    "        \n",
    "            # Arguments:\n",
    "                target: np.array\n",
    "                    array of target floating point numbers \n",
    "                pred: np.array\n",
    "                    array of predicted floating points numbers\n",
    "        '''\n",
    "        ################\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        loss = None\n",
    "\n",
    "        ################\n",
    "        return loss\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        if self.add_bias:\n",
    "            ################\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            x = np.hstack((np.ones_like(x), x))\n",
    "\n",
    "            ################\n",
    "\n",
    "        self.weights = self.initialize_weights(x.shape[1])\n",
    "\n",
    "        for i in range(self.num_iterations):\n",
    "            ################\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # step 1: calculate current_loss value\n",
    "\n",
    "            # step 2: calculate gradient value\n",
    "\n",
    "            # step 3: update weights using learning rate and gradient value\n",
    "\n",
    "            # step 4: calculate new_loss value\n",
    "\n",
    "            # step 5: if new_loss and current_loss difference is greater than max_error -> break;\n",
    "            #         if iteration is greater than max_iterations -> break\n",
    "        \n",
    "            ################\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' prediction function '''\n",
    "        ################\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        y_hat = # TODO\n",
    "\n",
    "        ################\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyLinearRegression()\n",
    "my_model.fit(x, y)\n",
    "y_hat = my_model.predict(x)\n",
    "\n",
    "plt.title('Data samples')\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_hat, color='r');\n",
    "\n",
    "print('My MSE: ', mean_squared_error(y, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
